{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions and Helpers\n",
    "Common helper functions and utilities for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def data_quality_report(df):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive data quality report.\n",
    "    \"\"\"\n",
    "    print(\"=== DATA QUALITY REPORT ===\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    print(\"\\nColumn Information:\")\n",
    "    for col in df.columns:\n",
    "        null_pct = (df[col].isnull().sum() / len(df)) * 100\n",
    "        unique_vals = df[col].nunique()\n",
    "        dtype = df[col].dtype\n",
    "        print(f\"  {col}: {dtype}, {null_pct:.1f}% null, {unique_vals} unique values\")\n",
    "    \n",
    "    print(\"\\nMissing Values Summary:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Missing %': missing_pct\n",
    "    })\n",
    "    print(missing_df[missing_df['Missing Count'] > 0])\n",
    "    \n",
    "    return missing_df\n",
    "\n",
    "# Test the function\n",
    "sample_data = pd.DataFrame({\n",
    "    'id': range(1, 101),\n",
    "    'name': ['User_' + str(i) for i in range(1, 101)],\n",
    "    'age': np.random.randint(18, 80, 100),\n",
    "    'salary': np.random.normal(50000, 15000, 100),\n",
    "    'department': np.random.choice(['IT', 'HR', 'Finance', 'Marketing'], 100)\n",
    "})\n",
    "\n",
    "# Add some missing values for demonstration\n",
    "sample_data.loc[sample_data.sample(10).index, 'salary'] = np.nan\n",
    "sample_data.loc[sample_data.sample(5).index, 'department'] = np.nan\n",
    "\n",
    "quality_report = data_quality_report(sample_data)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(sample_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(start_date, periods, freq='D', trend=0.1, seasonality=True, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Generate synthetic time series data with trend and seasonality.\n",
    "    \"\"\"\n",
    "    dates = pd.date_range(start=start_date, periods=periods, freq=freq)\n",
    "    \n",
    "    # Base trend\n",
    "    trend_component = np.arange(periods) * trend\n",
    "    \n",
    "    # Seasonal component\n",
    "    if seasonality:\n",
    "        seasonal_component = 10 * np.sin(2 * np.pi * np.arange(periods) / 365.25)\n",
    "    else:\n",
    "        seasonal_component = 0\n",
    "    \n",
    "    # Random noise\n",
    "    noise = np.random.normal(0, noise_level * 10, periods)\n",
    "    \n",
    "    # Combine components\n",
    "    values = 100 + trend_component + seasonal_component + noise\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'value': values,\n",
    "        'trend': trend_component,\n",
    "        'seasonal': seasonal_component,\n",
    "        'noise': noise\n",
    "    })\n",
    "\n",
    "# Generate and visualize time series\n",
    "ts_data = generate_time_series('2022-01-01', 730, trend=0.05, seasonality=True)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Original time series\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(ts_data['date'], ts_data['value'])\n",
    "plt.title('Generated Time Series')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Components\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(ts_data['date'], ts_data['trend'], label='Trend')\n",
    "plt.plot(ts_data['date'], ts_data['seasonal'], label='Seasonal')\n",
    "plt.title('Time Series Components')\n",
    "plt.legend()\n",
    "plt.ylabel('Component Value')\n",
    "\n",
    "# Distribution\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(ts_data['value'], bins=50, alpha=0.7)\n",
    "plt.title('Value Distribution')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Monthly aggregation\n",
    "plt.subplot(2, 2, 4)\n",
    "monthly_avg = ts_data.set_index('date').resample('M')['value'].mean()\n",
    "plt.plot(monthly_avg.index, monthly_avg.values, marker='o')\n",
    "plt.title('Monthly Average')\n",
    "plt.ylabel('Average Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTime series generated with {len(ts_data)} data points\")\n",
    "print(f\"Date range: {ts_data['date'].min()} to {ts_data['date'].max()}\")\n",
    "print(f\"Value range: {ts_data['value'].min():.2f} to {ts_data['value'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Calculate and display comprehensive performance metrics.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Create performance summary\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['MSE', 'RMSE', 'MAE', 'RÂ²'],\n",
    "        'Value': [mse, rmse, mae, r2]\n",
    "    })\n",
    "    \n",
    "    print(f\"Performance Metrics for {model_name}:\")\n",
    "    print(metrics_df.round(4))\n",
    "    \n",
    "    # Create residual plots\n",
    "    residuals = y_true - y_pred\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Actual vs Predicted\n",
    "    axes[0].scatter(y_true, y_pred, alpha=0.6)\n",
    "    axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "    axes[0].set_xlabel('Actual')\n",
    "    axes[0].set_ylabel('Predicted')\n",
    "    axes[0].set_title('Actual vs Predicted')\n",
    "    \n",
    "    # Residuals vs Predicted\n",
    "    axes[1].scatter(y_pred, residuals, alpha=0.6)\n",
    "    axes[1].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('Residuals')\n",
    "    axes[1].set_title('Residuals vs Predicted')\n",
    "    \n",
    "    # Residuals distribution\n",
    "    axes[2].hist(residuals, bins=30, alpha=0.7)\n",
    "    axes[2].set_xlabel('Residuals')\n",
    "    axes[2].set_ylabel('Frequency')\n",
    "    axes[2].set_title('Residuals Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "# Generate sample predictions for demonstration\n",
    "np.random.seed(42)\n",
    "y_true_sample = np.random.normal(100, 20, 200)\n",
    "y_pred_sample = y_true_sample + np.random.normal(0, 5, 200)  # Add some prediction error\n",
    "\n",
    "metrics_result = performance_metrics(y_true_sample, y_pred_sample, \"Sample Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}